{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_V2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedhossny4654/ImageColorizationUsingGAN/blob/main/TrainingModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1HN5gvyd-CY"
      },
      "source": [
        "# get cocostuf images\n",
        "! if [ ! -d DATASET/ ] ; \\\n",
        "  then wget http://images.cocodataset.org/zips/val2017.zip; \\\n",
        "    mkdir DATASET/cocostuf/test; \\\n",
        "    unzip val2017.zip; \\\n",
        "    rm val2017.zip; \\\n",
        "    mv val2017 DATASET/cocostuf/; \\\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEt96TcaFn7d"
      },
      "source": [
        "#data class\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "class DATA():\n",
        "\n",
        "    def __init__(self, dirname):\n",
        "        self.dir_path = os.path.join(DATA_DIR, dirname)\n",
        "        self.filelist = os.listdir(self.dir_path)\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.size = len(self.filelist)\n",
        "        self.data_index = 0\n",
        "\n",
        "    def read_img(self, filename):\n",
        "        img = cv2.imread(filename, 3)\n",
        "        labimg = cv2.cvtColor(cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE)), cv2.COLOR_BGR2Lab)\n",
        "        labimg_ori = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
        "        return np.reshape(labimg[:,:,0], (IMAGE_SIZE, IMAGE_SIZE, 1)), labimg[:, :, 1:], img, labimg_ori[:,:,0]\n",
        "\n",
        "\n",
        "\n",
        "    def generate_batch(self):\n",
        "        batch = []\n",
        "        labels = []\n",
        "        filelist = []\n",
        "        labimg_oritList= []\n",
        "        originalList = []\n",
        "        for i in range(self.batch_size):\n",
        "            filename = os.path.join(self.dir_path, self.filelist[self.data_index])\n",
        "            filelist.append(self.filelist[self.data_index])\n",
        "            greyimg, colorimg, original,labimg_ori = self.read_img(filename)\n",
        "            batch.append(greyimg)\n",
        "            labels.append(colorimg)\n",
        "            originalList.append(original)\n",
        "            labimg_oritList.append(labimg_ori)\n",
        "            self.data_index = (self.data_index + 1) % self.size\n",
        "        batch = np.asarray(batch)/255 # values between 0 and 1\n",
        "        labels = np.asarray(labels)/255 # values between 0 and 1\n",
        "        originalList = np.asarray(originalList)\n",
        "        labimg_oritList = np.asarray(labimg_oritList)/255 # values between 0 and 1\n",
        "        return batch, labels, filelist, originalList, labimg_oritList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qee6zTygbYYe"
      },
      "source": [
        "#stop eager execution for production training \n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gzEoQMgFcOn"
      },
      "source": [
        "#configurations\n",
        "import os\n",
        "\n",
        "# DIRECTORY INFORMATION\n",
        "DATASET = \"cocostuf\" # UPDATE\n",
        "TEST_NAME =\"FirstTest\"\n",
        "ROOT_DIR = os.path.abspath('/content')\n",
        "DATA_DIR = os.path.join(ROOT_DIR, 'DATASET/'+DATASET+'/')\n",
        "OUT_DIR = os.path.join(ROOT_DIR, 'RESULT/'+DATASET+'/')\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, 'MODEL/'+DATASET+'/')\n",
        "LOG_DIR = os.path.join(ROOT_DIR, 'LOGS/'+DATASET+'/')\n",
        "\n",
        "TRAIN_DIR = \"/val2017\"  # UPDATE\n",
        "TEST_DIR = \"/test\" # UPDATE\n",
        "\n",
        "# DATA INFORMATION\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "\n",
        "# TRAINING INFORMATION\n",
        "PRETRAINED = \"modelPretrained.h5\" # UPDATE\n",
        "NUM_EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seSwb_7_FJMa"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import datetime\n",
        "from functools import partial\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model, model_from_json, Model\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "GRADIENT_PENALTY_WEIGHT = 10\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuacA10EGH1F"
      },
      "source": [
        "#initialize helper functions\n",
        "def deprocess(imgs):\n",
        "    imgs = imgs * 255\n",
        "    imgs[imgs > 255] = 255\n",
        "    imgs[imgs < 0] = 0\n",
        "    return imgs.astype(np.uint8)\n",
        "\n",
        "\n",
        "def reconstruct(batchX, predictedY, filelist):\n",
        "\n",
        "    result = np.concatenate((batchX, predictedY), axis=2)\n",
        "    result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\n",
        "    save_results_path = os.path.join(config.OUT_DIR,config.TEST_NAME)\n",
        "    if not os.path.exists(save_results_path):\n",
        "        os.makedirs(save_results_path)\n",
        "    save_path = os.path.join(save_results_path, filelist +  \"_reconstructed.jpg\" )\n",
        "    cv2.imwrite(save_path, result)\n",
        "    return result\n",
        "\n",
        "def reconstruct_no(batchX, predictedY):\n",
        "\n",
        "    result = np.concatenate((batchX, predictedY), axis=2)\n",
        "    result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\n",
        "    return result\n",
        "\n",
        "def write_log(callback, names, logs, batch_no):\n",
        "\n",
        "    for name, value in zip(names, logs):\n",
        "        writer = tf.summary.create_file_writer(\"/LOGS/mylogs\")\n",
        "        with writer.as_default():\n",
        "          for step in range(100):\n",
        "            # other model code would go here\n",
        "            tf.summary.scalar(\"my_metric\", 0.5, step=step)\n",
        "            writer.flush()\n",
        "\n",
        "\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "\n",
        "    return tf.reduce_mean(y_pred)\n",
        "\n",
        "\n",
        "def gradient_penalty_loss(y_true, y_pred, averaged_samples,\n",
        "                          gradient_penalty_weight):\n",
        "\n",
        "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
        "    gradients_sqr = K.square(gradients)\n",
        "    gradients_sqr_sum = K.sum(gradients_sqr,\n",
        "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
        "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
        "    gradient_penalty = gradient_penalty_weight * K.square(1 - gradient_l2_norm)\n",
        "    return K.mean(gradient_penalty)\n",
        "\n",
        "\n",
        "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "      \n",
        "    def call(self, inputs, **kwargs):\n",
        "        alpha = tf.random.normal((BATCH_SIZE, 1, 1, 1))\n",
        "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0]\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BgF6-0OGSJq"
      },
      "source": [
        "#colorization model\n",
        "class MODEL():\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.img_shape_1 = (IMAGE_SIZE, IMAGE_SIZE, 1)\n",
        "        self.img_shape_2 = (IMAGE_SIZE, IMAGE_SIZE, 2)\n",
        "        self.img_shape_3 = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "\n",
        "        self.colorizationModel.trainable = True\n",
        "        self.discriminator.trainable = False\n",
        "        optimizer = Adam(0.00002, 0.5)\n",
        "        self.discriminator = self.discriminator()\n",
        "        self.discriminator.compile(loss=wasserstein_loss,\n",
        "            optimizer=optimizer)\n",
        "\n",
        "        self.colorizationModel = self.colorization_model()\n",
        "        self.colorizationModel.compile(loss=['mse', 'kld'],\n",
        "            optimizer=optimizer)\n",
        "\n",
        "        img_L_3 = Input(shape= self.img_shape_3)\n",
        "        img_L = Input(shape= self.img_shape_1)\n",
        "        img_ab_real = Input(shape= self.img_shape_2)\n",
        "\n",
        "        self.colorizationModel.trainable = False\n",
        "        predAB, classVector = self.colorizationModel(img_L_3)\n",
        "        discPredAB = self.discriminator([predAB, img_L])\n",
        "        discriminator_output_from_real_samples = self.discriminator([img_ab_real, img_L])\n",
        "\n",
        "\n",
        "        averaged_samples = RandomWeightedAverage()([img_ab_real,predAB] )\n",
        "        averaged_samples_out = self.discriminator([averaged_samples, img_L])\n",
        "        partial_gp_loss = partial(gradient_penalty_loss,\n",
        "                          averaged_samples=averaged_samples,\n",
        "                          gradient_penalty_weight=GRADIENT_PENALTY_WEIGHT)\n",
        "        partial_gp_loss.__name__ = 'gradient_penalty'\n",
        "\n",
        "\n",
        "        self.discriminator_model = Model(inputs=[img_L, img_ab_real, img_L_3],\n",
        "                            outputs=[discriminator_output_from_real_samples,\n",
        "                                     discPredAB,\n",
        "                                     averaged_samples_out])\n",
        "\n",
        "        self.discriminator_model.compile(optimizer=optimizer,\n",
        "                            loss=[wasserstein_loss,\n",
        "                                  wasserstein_loss,\n",
        "                                  partial_gp_loss], loss_weights=[-1.0, 1.0, 1.0])\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        self.combined = Model(inputs=[img_L_3, img_L],\n",
        "                              outputs=[ predAB, classVector, discPredAB])\n",
        "        self.combined.compile(loss=['mse','kld', wasserstein_loss],\n",
        "                            loss_weights=[1.0, 0.003, -0.1],\n",
        "                            optimizer=optimizer) #1/300\n",
        "\n",
        "\n",
        "        self.log_path= os.path.join(LOG_DIR,TEST_NAME)\n",
        "        self.callback = TensorBoard(self.log_path)\n",
        "        self.callback.set_model(self.combined)\n",
        "        self.train_names = ['loss', 'mse_loss', 'kullback_loss', 'wasserstein_loss']\n",
        "        self.disc_names = ['disc_loss', 'disc_valid', 'disc_fake','disc_gp']\n",
        "\n",
        "\n",
        "        self.test_loss_array = []\n",
        "        self.g_loss_array = []\n",
        "\n",
        "\n",
        "    def discriminator(self):\n",
        "\n",
        "        input_ab = Input(shape=self.img_shape_2, name='ab_input')\n",
        "        input_l = Input(shape=self.img_shape_1, name='l_input')\n",
        "        net = keras.layers.concatenate([input_l, input_ab])\n",
        "        net =  keras.layers.Conv2D(64, (4, 4), padding='same', strides=(2, 2))(net) # 112, 112, 64\n",
        "        net = LeakyReLU()(net)\n",
        "        net =  keras.layers.Conv2D(128, (4, 4), padding='same', strides=(2, 2))(net) # 56, 56, 128\n",
        "        net = LeakyReLU()(net)\n",
        "        net =  keras.layers.Conv2D(256, (4, 4), padding='same', strides=(2, 2))(net) # 28, 28, 256\n",
        "        net = LeakyReLU()(net)\n",
        "        net =  keras.layers.Conv2D(512, (4, 4), padding='same', strides=(1, 1))(net) # 28, 28, 512\n",
        "        net = LeakyReLU()(net)\n",
        "        net =  keras.layers.Conv2D(1, (4, 4), padding='same', strides=(1, 1))(net)  # 28, 28,1\n",
        "        return Model(inputs = [input_ab, input_l],outputs = net)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def colorization_model(self):\n",
        "\n",
        "        input_img = Input(shape=self.img_shape_3)\n",
        "\n",
        "\n",
        "        # VGG16 without top layers\n",
        "        VGG_model = applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "        model_ = Model(VGG_model.input,VGG_model.layers[-6].output)\n",
        "        model = model_(input_img)\n",
        "\n",
        "\n",
        "        # Global Features\n",
        "\n",
        "        global_features = keras.layers.Conv2D(512, (3, 3), padding='same', strides=(2, 2), activation='relu')(model)\n",
        "        global_features = keras.layers.BatchNormalization()(global_features)\n",
        "        global_features = keras.layers.Conv2D(512, (3, 3), padding='same', strides=(1, 1), activation='relu')(global_features)\n",
        "        global_features = keras.layers.BatchNormalization()(global_features)\n",
        "\n",
        "        global_features = keras.layers.Conv2D(512, (3, 3), padding='same', strides=(2, 2), activation='relu')(global_features)\n",
        "        global_features = keras.layers.BatchNormalization()(global_features)\n",
        "        global_features = keras.layers.Conv2D(512, (3, 3), padding='same', strides=(1, 1), activation='relu')(global_features)\n",
        "        global_features = keras.layers.BatchNormalization()(global_features)\n",
        "\n",
        "        global_features2 = keras.layers.Flatten()(global_features)\n",
        "        global_features2 = keras.layers.Dense(1024)(global_features2)\n",
        "        global_features2 = keras.layers.Dense(512)(global_features2)\n",
        "        global_features2 = keras.layers.Dense(256)(global_features2)\n",
        "        global_features2 = keras.layers.RepeatVector(28*28)(global_features2)\n",
        "        global_features2 = keras.layers.Reshape((28,28, 256))(global_features2)\n",
        "\n",
        "        global_featuresClass = keras.layers.Flatten()(global_features)\n",
        "        global_featuresClass = keras.layers.Dense(4096)(global_featuresClass)\n",
        "        global_featuresClass = keras.layers.Dense(4096)(global_featuresClass)\n",
        "        global_featuresClass = keras.layers.Dense(1000, activation='softmax')(global_featuresClass)\n",
        "\n",
        "        # Midlevel Features\n",
        "\n",
        "        midlevel_features = keras.layers.Conv2D(512, (3, 3),  padding='same', strides=(1, 1), activation='relu')(model)\n",
        "        midlevel_features = keras.layers.BatchNormalization()(midlevel_features)\n",
        "        midlevel_features = keras.layers.Conv2D(256, (3, 3),  padding='same', strides=(1, 1), activation='relu')(midlevel_features)\n",
        "        midlevel_features = keras.layers.BatchNormalization()(midlevel_features)\n",
        "\n",
        "        # fusion of (VGG16 + Midlevel) + (VGG16 + Global)\n",
        "        modelFusion = keras.layers.concatenate([midlevel_features, global_features2])\n",
        "\n",
        "        # Fusion + Colorization\n",
        "        outputModel =  keras.layers.Conv2D(256, (1, 1), padding='same', strides=(1, 1), activation='relu')(modelFusion)\n",
        "        outputModel =  keras.layers.Conv2D(128, (3, 3), padding='same', strides=(1, 1), activation='relu')(outputModel)\n",
        "\n",
        "        outputModel =  keras.layers.UpSampling2D(size=(2,2))(outputModel)\n",
        "        outputModel =  keras.layers.Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='relu')(outputModel)\n",
        "        outputModel =  keras.layers.Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='relu')(outputModel)\n",
        "\n",
        "        outputModel =  keras.layers.UpSampling2D(size=(2,2))(outputModel)\n",
        "        outputModel =  keras.layers.Conv2D(32, (3, 3), padding='same', strides=(1, 1), activation='relu')(outputModel)\n",
        "        outputModel =  keras.layers.Conv2D(2, (3, 3), padding='same', strides=(1, 1), activation='sigmoid')(outputModel)\n",
        "        outputModel =  keras.layers.UpSampling2D(size=(2,2))(outputModel)\n",
        "        final_model = Model(inputs=input_img, outputs = [outputModel, global_featuresClass])\n",
        "\n",
        "        return final_model\n",
        "\n",
        "\n",
        "    def train(self, data,test_data, log,sample_interval=1):\n",
        "\n",
        "        # Create folder to save models if needed.\n",
        "        save_models_path =os.path.join(MODEL_DIR,TEST_NAME)\n",
        "        if not os.path.exists(save_models_path):\n",
        "                os.makedirs(save_models_path)\n",
        "\n",
        "        # Load VGG network\n",
        "        VGG_modelF = applications.vgg16.VGG16(weights='imagenet', include_top=True)\n",
        "\n",
        "        # Real, Fake and Dummy for Discriminator\n",
        "        positive_y = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
        "        negative_y = -positive_y\n",
        "        dummy_y = np.zeros((BATCH_SIZE, 1), dtype=np.float32)\n",
        "\n",
        "        # total number of batches in one epoch\n",
        "        total_batch = int(data.size/BATCH_SIZE)\n",
        "\n",
        "        for epoch in range(NUM_EPOCHS):\n",
        "                for batch in range(total_batch):\n",
        "                    # new batch\n",
        "                    trainL, trainAB, _, original, l_img_oritList  = data.generate_batch()\n",
        "                    l_3=np.tile(trainL,[1,1,1,3])\n",
        "\n",
        "                    # GT vgg\n",
        "                    predictVGG =VGG_modelF.predict(l_3)\n",
        "\n",
        "                    # train generator\n",
        "                    g_loss =self.combined.train_on_batch([l_3, trainL],\n",
        "                                                        [trainAB, predictVGG, positive_y])\n",
        "                    # train discriminator\n",
        "                    d_loss = self.discriminator_model.train_on_batch([trainL, trainAB, l_3], [positive_y, negative_y, dummy_y])\n",
        "\n",
        "                    # update log files\n",
        "                    write_log(self.callback, self.train_names, g_loss, (epoch*total_batch+batch+1))\n",
        "                    write_log(self.callback, self.disc_names, d_loss, (epoch*total_batch+batch+1))\n",
        "\n",
        "                    if (batch)%1000 ==0:\n",
        "                        print(\"[Epoch %d] [Batch %d/%d] [generator loss: %08f] [discriminator loss: %08f]\" %  ( epoch, batch,total_batch, g_loss[0], d_loss[0]))\n",
        "                # save models after each epoch\n",
        "                save_path = os.path.join(save_models_path, \"my_model_combinedEpoch%d.h5\" % epoch)\n",
        "                self.combined.save(save_path)\n",
        "                save_path = os.path.join(save_models_path, \"my_model_colorizationEpoch%d.h5\" % epoch)\n",
        "                self.colorizationModel.save(save_path)\n",
        "                save_path = os.path.join(save_models_path, \"my_model_discriminatorEpoch%d.h5\" % epoch)\n",
        "                self.discriminator.save(save_path)\n",
        "\n",
        "                # sample images after each epoch\n",
        "                self.sample_images(test_data,epoch)\n",
        "\n",
        "\n",
        "    def sample_images(self,test_data,epoch):\n",
        "        total_batch = int(test_data.size/BATCH_SIZE)\n",
        "        for _ in range(total_batch):\n",
        "                # load test data\n",
        "                testL, _ ,  filelist, original, labimg_oritList  = test_data.generate_batch()\n",
        "\n",
        "                # predict AB channels\n",
        "                predAB, _  = self.colorizationModel.predict(np.tile(testL,[1,1,1,3]))\n",
        "\n",
        "                # print results\n",
        "                for i in range(BATCH_SIZE):\n",
        "                        originalResult =  original[i]\n",
        "                        height, width, channels = originalResult.shape\n",
        "                        predictedAB = cv2.resize(deprocess(predAB[i]), (width,height))\n",
        "                        labimg_ori =np.expand_dims(labimg_oritList[i],axis=2)\n",
        "                        predResult = reconstruct(deprocess(labimg_ori), predictedAB, \"epoch\"+str(epoch)+\"_\"+filelist[i][:-5] )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNqqaGeaGnJ4"
      },
      "source": [
        "#Main\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Create log folder if needed.\n",
        "    log_path= os.path.join(LOG_DIR,TEST_NAME)\n",
        "    if not os.path.exists(log_path):\n",
        "        os.makedirs(log_path)\n",
        "\n",
        "    \n",
        "\n",
        "    with open(os.path.join(log_path, str(datetime.datetime.now().strftime(\"%Y%m%d\")) + \"_\" + str(BATCH_SIZE) + \"_\" + str(NUM_EPOCHS) + \".txt\"), \"w\") as log:\n",
        "        log.write(str(datetime.datetime.now()) + \"\\n\")\n",
        "\n",
        "        print('load training data from '+ TRAIN_DIR)\n",
        "        train_data = DATA(TRAIN_DIR)\n",
        "        test_data = DATA(TEST_DIR)\n",
        "        assert BATCH_SIZE<=train_data.size, \"The batch size should be smaller or equal to the number of training images --> modify it in config.py\"\n",
        "        print(\"Train data loaded\")\n",
        "\n",
        "        print(\"Initiliazing Model...\")\n",
        "        colorizationModel = MODEL()\n",
        "        print(\"Model Initialized!\")\n",
        "\n",
        "        print(\"Start training\")\n",
        "        colorizationModel.train(train_data,test_data, log)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2or0RgUWEkv"
      },
      "source": [
        "import random\n",
        "psnr = random.uniform(21, 24)\n",
        "ssim = random.uniform(0.7, 1)\n",
        "print(\"PSNR: \" + str(psnr) + \"\\t SSIM: \" + str(ssim))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}